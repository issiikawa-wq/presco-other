import os
import time
import csv
import json
import re
from datetime import datetime

from playwright.sync_api import sync_playwright
from playwright._impl._errors import Error as PlaywrightError

import gspread
from oauth2client.service_account import ServiceAccountCredentials


# ==========================================
# æœŸé–“æŒ‡å®šCSVå–å¾—
# ==========================================
def download_csv_for_period(page, period, save_path):

    print(f"{period} ã‚’é¸æŠ")

    if period == "yesterday":
        page.click('a[onclick="setYesterday()"]', timeout=10000)
    elif period == "today":
        page.click('a[onclick="setToday()"]', timeout=10000)

    time.sleep(1)

    # ğŸ”¥ æ¤œç´¢ãƒœã‚¿ãƒ³ï¼ˆdivå¯¾å¿œï¼‰
    page.click('.filter-button--submit', timeout=10000)
    time.sleep(5)

    page.wait_for_selector("#csv-link", timeout=30000)

    with page.expect_download(timeout=60000) as download_info:
        page.click("#csv-link")

    download = download_info.value
    download.save_as(save_path)

    print(f"{period} CSVä¿å­˜å®Œäº†")


# ==========================================
# ãƒ­ã‚°ã‚¤ãƒ³ï¼†2æ—¥åˆ†å–å¾—
# ==========================================
def login_and_download():

    email = os.getenv("PRESCO_EMAIL")
    password = os.getenv("PRESCO_PASSWORD")

    with sync_playwright() as p:

        browser = p.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-setuid-sandbox",
                "--disable-blink-features=AutomationControlled",
            ]
        )

        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                       "AppleWebKit/537.36 (KHTML, like Gecko) "
                       "Chrome/120.0.0.0 Safari/537.36"
        )

        page = context.new_page()

        try:
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸
            for i in range(3):
                try:
                    page.goto("https://presco.ai/partner/", timeout=60000)
                    break
                except PlaywrightError:
                    print("ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸å†è©¦è¡Œ")
                    time.sleep(5)

            page.wait_for_selector('input[name="username"]', timeout=30000)

            page.fill('input[name="username"]', email)
            page.fill('input[name="password"]', password)

            with page.expect_navigation(timeout=60000):
                page.click('input[type="submit"]')

            print("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")

            # æˆæœä¸€è¦§ãƒšãƒ¼ã‚¸
            page.goto("https://presco.ai/partner/actionLog/list", timeout=60000)
            page.wait_for_load_state("networkidle")
            time.sleep(3)

            # æˆæœç™ºç”Ÿæ—¥æ™‚ã«å¤‰æ›´
            selectors = [
                'input[name="dateType"][value="actionDate"]',
                'input[type="radio"][value="actionDate"]',
                'label:has-text("æˆæœç™ºç”Ÿæ—¥æ™‚")'
            ]

            for selector in selectors:
                try:
                    page.click(selector, timeout=5000)
                    break
                except:
                    continue

            time.sleep(1)

            yesterday_path = "/tmp/presco_yesterday.csv"
            today_path = "/tmp/presco_today.csv"

            download_csv_for_period(page, "yesterday", yesterday_path)
            download_csv_for_period(page, "today", today_path)

            return yesterday_path, today_path

        finally:
            browser.close()


# ==========================================
# CSVãƒãƒ¼ã‚¸
# ==========================================
def extract_gclid(url):
    if not url:
        return ""
    match = re.search(r"gclid=([^&]+)", url)
    return match.group(1) if match else ""


def merge_csv(yesterday_path, today_path):

    target_sites = ["Fast Baito ä»‹è­·ç‰¹åŒ–", "Fast Baito"]

    results = []
    results.append(["Parameters:TimeZone=Asia/Tokyo"])
    results.append([
        "Google Click ID",
        "Conversion Name",
        "Conversion Time",
        "Conversion Value",
        "Conversion Currency"
    ])

    seen = set()

    for path in [yesterday_path, today_path]:

        with open(path, "r", encoding="shift_jis", errors="ignore") as f:
            reader = list(csv.reader(f))

        data = reader[1:]

        for row in data:

            if len(row) < 18:
                continue

            site = row[5]
            if site not in target_sites:
                continue

            gclid = extract_gclid(row[12])
            if not gclid:
                continue

            if gclid in seen:
                continue

            seen.add(gclid)

            action_datetime = row[3]

            if site == "Fast Baito ä»‹è­·ç‰¹åŒ–":
                value = "3000"
                conv_name = "ä»‹è­·ã‚ªãƒ•ãƒ©ã‚¤ãƒ³CV"
            else:
                value = str(int(float(row[17])))
                conv_name = "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³CV"

            results.append([
                gclid,
                conv_name,
                action_datetime,
                value,
                "JPY"
            ])

    print("æœ€çµ‚æŠ½å‡ºä»¶æ•°:", len(results) - 2)

    return results


# ==========================================
# Google Sheets
# ==========================================
def upload_to_sheet(data):

    creds_json = os.getenv("GOOGLE_CREDENTIALS")
    sheet_id = os.getenv("SPREADSHEET_ID")

    creds = json.loads(creds_json)

    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]

    credentials = ServiceAccountCredentials.from_json_keyfile_dict(creds, scope)
    gc = gspread.authorize(credentials)

    sh = gc.open_by_key(sheet_id)
    ws = sh.worksheet("æˆæœæƒ…å ±_ãã®ä»–")

    ws.clear()
    ws.update(values=data, range_name="A1")

    print("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›´æ–°å®Œäº†")


# ==========================================
# main
# ==========================================
def main():

    print("æ˜¨æ—¥ï¼‹ä»Šæ—¥ å–å¾—é–‹å§‹")

    yesterday_path, today_path = login_and_download()

    merged_data = merge_csv(yesterday_path, today_path)

    upload_to_sheet(merged_data)

    print("å®Œäº†")


if __name__ == "__main__":
    main()
